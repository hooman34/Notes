<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Mathematical intuition of gradient descent | Notes</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Mathematical intuition of gradient descent" />
<meta name="author" content="Gieun Kwak" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Understanding and coding gradient descent from scratch" />
<meta property="og:description" content="Understanding and coding gradient descent from scratch" />
<link rel="canonical" href="https://hooman34.github.io/Notes/optimization/gradient%20descent/2022/02/12/Mathematical_intution_of_gradient_descent.html" />
<meta property="og:url" content="https://hooman34.github.io/Notes/optimization/gradient%20descent/2022/02/12/Mathematical_intution_of_gradient_descent.html" />
<meta property="og:site_name" content="Notes" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-02-12T00:00:00-06:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Mathematical intuition of gradient descent" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Gieun Kwak"},"dateModified":"2022-02-12T00:00:00-06:00","datePublished":"2022-02-12T00:00:00-06:00","description":"Understanding and coding gradient descent from scratch","headline":"Mathematical intuition of gradient descent","mainEntityOfPage":{"@type":"WebPage","@id":"https://hooman34.github.io/Notes/optimization/gradient%20descent/2022/02/12/Mathematical_intution_of_gradient_descent.html"},"url":"https://hooman34.github.io/Notes/optimization/gradient%20descent/2022/02/12/Mathematical_intution_of_gradient_descent.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/Notes/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://hooman34.github.io/Notes/feed.xml" title="Notes" /><link rel="shortcut icon" type="image/x-icon" href="/Notes/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/Notes/">Notes</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/Notes/about/">About Me</a><a class="page-link" href="/Notes/search/">Search</a><a class="page-link" href="/Notes/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Mathematical intuition of gradient descent</h1><p class="page-description">Understanding and coding gradient descent from scratch</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2022-02-12T00:00:00-06:00" itemprop="datePublished">
        Feb 12, 2022
      </time>• 
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span class="p-author h-card" itemprop="name">Gieun Kwak</span></span>
       • <span class="read-time" title="Estimated read time">
    
    
      7 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/Notes/categories/#optimization">optimization</a>
        &nbsp;
      
        <a class="category-tags-link" href="/Notes/categories/#gradient descent">gradient descent</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-justify-center">
          <div class="px-2">

    <a href="https://github.com/hooman34/Notes/tree/master/_notebooks/2022-02-12-Mathematical_intution_of_gradient_descent.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/Notes/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/hooman34/Notes/master?filepath=_notebooks%2F2022-02-12-Mathematical_intution_of_gradient_descent.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/Notes/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/hooman34/Notes/blob/master/_notebooks/2022-02-12-Mathematical_intution_of_gradient_descent.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/Notes/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
          <div class="px-2">
  <a href="https://deepnote.com/launch?url=https%3A%2F%2Fgithub.com%2Fhooman34%2FNotes%2Fblob%2Fmaster%2F_notebooks%2F2022-02-12-Mathematical_intution_of_gradient_descent.ipynb" target="_blank">
      <img class="notebook-badge-image" src="/Notes/assets/badges/deepnote.svg" alt="Launch in Deepnote"/>
  </a>
</div>

        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul id="toc" class="section-nav">
<li class="toc-entry toc-h3"><a href="#1.-How-gradient-descent-looks-like">1. How gradient descent looks like </a></li>
<li class="toc-entry toc-h3"><a href="#2.-How-gradient-descent-works:-simple-maths">2. How gradient descent works: simple maths </a></li>
<li class="toc-entry toc-h3"><a href="#3.-How-is-gradient-calculated?">3. How is gradient calculated? </a></li>
<li class="toc-entry toc-h3"><a href="#4.-Newton's-method-from-scratch">4. Newton&#39;s method from scratch </a>
<ul>
<li class="toc-entry toc-h4"><a href="#Parameters">Parameters </a></li>
<li class="toc-entry toc-h4"><a href="#Code-walkthrough">Code walkthrough </a></li>
<li class="toc-entry toc-h4"><a href="#Coding---from-scratch">Coding - from scratch </a></li>
</ul>
</li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2022-02-12-Mathematical_intution_of_gradient_descent.ipynb
-->

<div class="container" id="notebook-container">
        
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sympy</span> <span class="kn">import</span> <span class="o">*</span>
<span class="c1"># from IPython.display import set_matplotlib_formats</span>
<span class="c1"># import matplotlib_inline.backend_inline</span>
<span class="c1"># matplotlib_inline.backend_inline.set_matplotlib_formats('png')</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="1.-How-gradient-descent-looks-like">
<a class="anchor" href="#1.-How-gradient-descent-looks-like" aria-hidden="true"><span class="octicon octicon-link"></span></a>1. How gradient descent looks like<a class="anchor-link" href="#1.-How-gradient-descent-looks-like"> </a>
</h3>
<p>Gradient descent is commonly used in ML and AI. Looking at the image below, we encounter from lectures that the gradient descent is a 'process of finding the most lowest point of the function'. While this is a very concise and accurate explanation of gradient descent, understanding it in a mathematical way would enable a deeper understanding.</p>
<p><img src="/Notes/images/copied_from_nb/my_icons/03_/gradient-descent-example.png" alt=""></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><br>
<br>
<br>
<br></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="2.-How-gradient-descent-works:-simple-maths">
<a class="anchor" href="#2.-How-gradient-descent-works:-simple-maths" aria-hidden="true"><span class="octicon octicon-link"></span></a>2. How gradient descent works: simple maths<a class="anchor-link" href="#2.-How-gradient-descent-works:-simple-maths"> </a>
</h3>
<p>The gradient descent image above goes through a line until it reaches the 'bottom' of the function. This 'bottom' of the function is called 'minimum'. We want to reach the minimum because it will give us the best values for our problem. One of the common use of gradient is when we estimate the parameters of a ML or AI model. We want to find the paramaters that has the smalles loss value (closes to the actual observation).</p>
<p>Lets consider a function $y = (x-5)^2$. We want to find the minimum value of this function by following a sequence of steps.</p>
<ol>
<li>Start from a certain point</li>
<li>Move to a new point that gives a better objective value (here, smaller values)</li>
<li>Repeat step 2</li>
</ol>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># x = np.arange(2, 8, 0.01)</span>
<span class="c1"># def y(x):</span>
<span class="c1">#     return (x-5)**2</span>

<span class="c1"># fig, ax = plt.subplots()</span>
<span class="c1"># ax.plot(x, y(x))</span>
<span class="c1"># ax.set_xlabel("x")</span>
<span class="c1"># ax.set_ylabel("y")</span>
<span class="c1"># ax.plot([5], y(5), marker='o', color='black')</span>

<span class="c1"># fig.savefig('my_icons/03_/one.png');</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="/Notes/images/copied_from_nb/my_icons/03_/one.png" alt=""></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>One thing most explanations exclude is the constraint. Actually, for every optimization problem, there is an objective function and a constraint. The objective function is $y = (x-5)^2$. And the constraint is hidden, which is $x \in R$, $y \in R$ ($R$ means real numbers).</p>
<p>The optimization problem changes along the constraints, but for now lets say the constraint is $y \geq (x-5)^2$. This means the set of potential solutions for this problem is all the points above the function line.</p>
<p>The process of gradient descent will only happen inside the blue area (points that satisfy the constraints)</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># x = np.arange(2, 8, 0.01)</span>
<span class="c1"># def y(x):</span>
<span class="c1">#     return (x-5)**2</span>

<span class="c1"># fig, ax = plt.subplots()</span>
<span class="c1"># ax.plot(x, y(x))</span>
<span class="c1"># ax.set_xlabel("x")</span>
<span class="c1"># ax.set_ylabel("y")</span>

<span class="c1"># ax.fill_between(x, y(x), 9, color='blue', alpha=.1)</span>
<span class="c1"># ax.plot([5], y(5), marker='o', color='black')</span>

<span class="c1"># fig.savefig('my_icons/03_/two.png')</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="/Notes/images/copied_from_nb/my_icons/03_/two.png" alt=""></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now lets say we start at a point where $x=7$ and $y=4$</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># x = np.arange(2, 8, 0.01)</span>
<span class="c1"># def y(x):</span>
<span class="c1">#     return (x-5)**2</span>

<span class="c1"># fig, ax = plt.subplots()</span>
<span class="c1"># ax.plot(x, y(x))</span>
<span class="c1"># ax.set_xlabel("x")</span>
<span class="c1"># ax.set_ylabel("y")</span>
<span class="c1"># ax.fill_between(x, y(x), 9, color='blue', alpha=.1)</span>

<span class="c1"># ax.plot([7], y(7), marker='o', color='red')</span>
<span class="c1"># ax.plot([5], y(5), marker='o', color='black')</span>

<span class="c1"># fig.savefig('my_icons/03_/three.png')</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="/Notes/images/copied_from_nb/my_icons/03_/three.png" alt=""></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This red dot can go anywhere as long as it is in the blue area. Lets say this dot moves to $(6,6)$. This point is still in the blue area and satisfies the constraint we have set. This is called feasibility.</p>
<ul>
<li><strong>The process of gradient descent ONLY considers the solutions that are feasible (satisfies constraints)</strong></li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># x = np.arange(2, 8, 0.01)</span>
<span class="c1"># def y(x):</span>
<span class="c1">#     return (x-5)**2</span>

<span class="c1"># fig, ax = plt.subplots()</span>
<span class="c1"># ax.plot(x, y(x))</span>
<span class="c1"># ax.set_xlabel("x")</span>
<span class="c1"># ax.set_ylabel("y")</span>
<span class="c1"># ax.fill_between(x, y(x), 9, color='blue', alpha=.1)</span>

<span class="c1"># ax.plot([7], y(7), marker='o', color='red')</span>
<span class="c1"># ax.plot([6], 6, marker='o', color='green')</span>
<span class="c1"># ax.plot([6], 2, marker='o', color='blue')</span>
<span class="c1"># ax.plot([5], y(5), marker='o', color='black')</span>

<span class="c1"># ax.arrow(7, y(7), 6-7+0.1, 2-y(7)+0.1, head_width=0.1, head_length=0.1);</span>

<span class="c1"># fig.savefig('my_icons/03_/four.png')</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="/Notes/images/copied_from_nb/my_icons/03_/four.png" alt=""></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>While the point $(6,6)$ is feasible, does it go to the optimal value? The optimal value we want to find is the smallest point of $y=(x-5)^2$.</p>
<p>Y value when x=7 : 4 <br>
Y value when x=6 : 6</p>
<p>The value of the function rather increased, and it means that this is not the right direction.</p>
<p>If the red dot goes to the direction of blue dot, the objective function decreases. This then would be the right direction we want to go. And the 'amount' we want to move is the learning rate($\lambda$) which is a small step towards the direction.</p>
<ul>
<li><strong>The solution for each step is updated by $x^1 = x^0 + \lambda d^0$, and the direction is where the optimal value gets closer to the global minimum.</strong></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><br>
<br>
<br>
<br></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="3.-How-is-gradient-calculated?">
<a class="anchor" href="#3.-How-is-gradient-calculated?" aria-hidden="true"><span class="octicon octicon-link"></span></a>3. How is gradient calculated?<a class="anchor-link" href="#3.-How-is-gradient-calculated?"> </a>
</h3>
<p>There are two aspects in calculating gradient. First is the 'direction', and the second is the 'distance'. <br> Lets say $d$ is for firection and $\alpha$ for step size ('distance'). Then this could be formulated as the following: $f(x^k + \alpha d^k) &lt; f(x^k)$, which means the new value is smaller than the current function value. <br>
Using Taylor's expanson, it could be formulated as $f(x^k + \alpha d^k) \approx f(x^k) + \alpha\nabla f(x^k)^T d_k$ <br>
Since $f(x^k + \alpha d^k) &lt; f(x^k)$, we want $\alpha\nabla f(x^k)^T d_k$ to be smaller than zero. The steepest direction $d_k$ would be $-\nabla f(x^k)$ since it is the opposite direction from $\nabla f(x^k)^T$</p>
<p>Then, the new point is updated every step by $x^{k+1} \leftarrow x_k - \alpha \nabla f(x_k)$</p>
<p>This process will continue until $||\nabla f(x_k)|| \leq \epsilon$ where $\epsilon$ is a very small number. This is the point where the gradient is small enough or vanishes. This means that there is no more 'movement'.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># x = np.arange(2, 8, 0.01)</span>
<span class="c1"># def y(x):</span>
<span class="c1">#     return (x-5)**2</span>

<span class="c1"># fig, ax = plt.subplots()</span>
<span class="c1"># ax.plot(x, y(x))</span>
<span class="c1"># ax.set_xlabel("x")</span>
<span class="c1"># ax.set_ylabel("y")</span>
<span class="c1"># ax.fill_between(x, y(x), 9, color='blue', alpha=.1)</span>

<span class="c1"># ax.plot([7], y(7), marker='o', color='red')</span>
<span class="c1"># ax.plot([5], y(5), marker='o', color='black')</span>

<span class="c1"># def line1(x):</span>
<span class="c1">#     return 4*x - 24</span>
<span class="c1"># def line2(x):</span>
<span class="c1">#     return x*0</span>

<span class="c1"># ax.plot(np.arange(6, 8, 0.01), line1(np.arange(6, 8, 0.01)), color='red')</span>
<span class="c1"># ax.plot(x, line2(x), color='black');</span>
<span class="c1"># fig.savefig('my_icons/03_/five.png')</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="/Notes/images/copied_from_nb/my_icons/03_/five.png" alt=""></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The red dot has a negative gradient, and it moves the point towards left. If the point reaches the black dot, the gradient is zero (vanishes), meaning there is no further direction for the point to move, indicating the end of the search.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><br>
<br>
<br>
<br></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="4.-Newton's-method-from-scratch">
<a class="anchor" href="#4.-Newton's-method-from-scratch" aria-hidden="true"><span class="octicon octicon-link"></span></a>4. Newton's method from scratch<a class="anchor-link" href="#4.-Newton's-method-from-scratch"> </a>
</h3>
<p>One of the methods of gradient descent is Newton's method.</p>
<p>Let $x^k$ be the current state and consider a second order Taylor approximation of $f(x)$. <br>
$g(x) = f(x^k)+\nabla f(x^k)^T (x-x^k) + \frac{1}{2}(x-x^k)\nabla^2f(x^k)(x-x^k)$</p>
<p>The next step would be to find the point that minimizes the function $g(x)$. That point would be where the first derivative equals to zero.
$\nabla g(x) = \nabla f(x^k)+\nabla^2f(x^k)(x-x^k) = 0$</p>
<p>Solving this equation for $x$, this gives us <br>
$x = x^k - [\nabla^2f(x_k)]^{-1} \nabla f(x^k)$ which will be the new $x^{k+1}$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><br>
<br></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>To formulate this into the code, here is the psuedo code.</p>
<p><img src="/Notes/images/copied_from_nb/my_icons/03_/newtons_method.png" alt=""></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Parameters">
<a class="anchor" href="#Parameters" aria-hidden="true"><span class="octicon octicon-link"></span></a>Parameters<a class="anchor-link" href="#Parameters"> </a>
</h4>
<ul>
<li>$k$ is the indicator for current step </li>
<li>$\epsilon$ is the minimum value for stopping the search</li>
<li>$\alpha$ is the step size. $\alpha$ changes via line search. This means that we want to find a step size that actually leads to minimizing the function value</li>
<li>$\rho$ and $c$ are scalars used to derive $\alpha$ during line search. They are between 0 and 1</li>
</ul>
<h4 id="Code-walkthrough">
<a class="anchor" href="#Code-walkthrough" aria-hidden="true"><span class="octicon octicon-link"></span></a>Code walkthrough<a class="anchor-link" href="#Code-walkthrough"> </a>
</h4>
<ul>
<li>Set the initial values for $\alpha$, $d$, $k$. Initial starting point $x^0$ will be provided via input</li>
<li>The search ends only if the first derivative of $f(x)$ is smaller than $\epsilon$. Here, it is actually the norm value of the vector.</li>
<li>Inside the search, first determine perform line search to find $\alpha$<ul>
<li>If $\alpha$ is found, update $x^{k+1}$ as well as $d^{k+1}$</li>
</ul>
</li>
<li>Continue until vanishing gradient or when it is small enough</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Coding---from-scratch">
<a class="anchor" href="#Coding---from-scratch" aria-hidden="true"><span class="octicon octicon-link"></span></a>Coding - from scratch<a class="anchor-link" href="#Coding---from-scratch"> </a>
</h4>
<p>Lets solve the optimzal minimum value for the following function.

$$y = 100(x_2-x_1^2)^2 + (1-x_1)^2$$
</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">plot_contour_2d</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">7</span><span class="p">))</span>

    <span class="n">c_plot</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">contour</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">clabel</span><span class="p">(</span><span class="n">c_plot</span><span class="p">,</span> <span class="n">inline</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
              <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">);</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">'2D contour plot'</span><span class="p">);</span>
    
<span class="k">def</span> <span class="nf">plot_contour_3d</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">save_dir</span><span class="p">):</span>
    <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">7</span><span class="p">))</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">axes</span><span class="p">(</span><span class="n">projection</span><span class="o">=</span><span class="s1">'3d'</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">contour3D</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'binary'</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">"x1"</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">"x2"</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_zlabel</span><span class="p">(</span><span class="s2">"y"</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">'3D contour plot'</span><span class="p">);</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># X1 = np.arange(-50, 50, 0.1)</span>
<span class="c1"># X2 = np.arange(-50, 20, 0.1)</span>
<span class="c1"># X1, X2 = np.meshgrid(X1, X2)</span>
<span class="c1"># y = 100 * (X2 - X1**2)**2 + (1-X1)**2</span>

<span class="c1"># plot_contour_3d(X1, X2, y, 'my_icons/03_/3D_contour.png')</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="/Notes/images/copied_from_nb/my_icons/03_/3D_contour.png" alt=""></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<p>END</p>

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="hooman34/Notes"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/Notes/optimization/gradient%20descent/2022/02/12/Mathematical_intution_of_gradient_descent.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/Notes/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/Notes/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/Notes/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>All the learnings, distilled here.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/fastai" target="_blank" title="fastai"><svg class="svg-icon grey"><use xlink:href="/Notes/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/fastdotai" target="_blank" title="fastdotai"><svg class="svg-icon grey"><use xlink:href="/Notes/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
